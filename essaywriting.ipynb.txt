{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"},{"sourceId":7378735,"sourceType":"datasetVersion","datasetId":4287904},{"sourceId":158756547,"sourceType":"kernelVersion"}],"dockerImageVersionId":30627,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-14T19:39:05.846455Z","iopub.execute_input":"2024-01-14T19:39:05.846909Z","iopub.status.idle":"2024-01-14T19:39:05.857199Z","shell.execute_reply.started":"2024-01-14T19:39:05.846882Z","shell.execute_reply":"2024-01-14T19:39:05.856121Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/essaywriting2/__results__.html\n/kaggle/input/essaywriting2/__resultx__.html\n/kaggle/input/essaywriting2/__notebook__.ipynb\n/kaggle/input/essaywriting2/__output__.json\n/kaggle/input/essaywriting2/custom.css\n/kaggle/input/essaywriting2/bert_base_uncased/config.json\n/kaggle/input/essaywriting2/bert_base_uncased/tokenizer_config.json\n/kaggle/input/essaywriting2/bert_base_uncased/model.safetensors\n/kaggle/input/essaywriting2/bert_base_uncased/special_tokens_map.json\n/kaggle/input/essaywriting2/bert_base_uncased/vocab.txt\n/kaggle/input/llm-detect-ai-generated-text/sample_submission.csv\n/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\n/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\n/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\n/kaggle/input/human-vs-llm-text-corpus/distribution.parquet\n/kaggle/input/human-vs-llm-text-corpus/data.parquet\n/kaggle/input/human-vs-llm-text-corpus/distribution.csv\n/kaggle/input/human-vs-llm-text-corpus/prompts.csv\n/kaggle/input/human-vs-llm-text-corpus/data.csv\n/kaggle/input/human-vs-llm-text-corpus/prompts.parquet\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 1. Importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import re\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:39:05.859016Z","iopub.execute_input":"2024-01-14T19:39:05.859768Z","iopub.status.idle":"2024-01-14T19:39:12.819643Z","shell.execute_reply.started":"2024-01-14T19:39:05.859714Z","shell.execute_reply":"2024-01-14T19:39:12.818830Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 2. Data Inspection and Visualization","metadata":{}},{"cell_type":"code","source":"train_prompts = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv\")\ntrain_prompts.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:39:12.820764Z","iopub.execute_input":"2024-01-14T19:39:12.821239Z","iopub.status.idle":"2024-01-14T19:39:12.848790Z","shell.execute_reply.started":"2024-01-14T19:39:12.821210Z","shell.execute_reply":"2024-01-14T19:39:12.847804Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   prompt_id                       prompt_name  \\\n0          0                   Car-free cities   \n1          1  Does the electoral college work?   \n\n                                        instructions  \\\n0  Write an explanatory essay to inform fellow ci...   \n1  Write a letter to your state senator in which ...   \n\n                                         source_text  \n0  # In German Suburb, Life Goes On Without Cars ...  \n1  # What Is the Electoral College? by the Office...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt_id</th>\n      <th>prompt_name</th>\n      <th>instructions</th>\n      <th>source_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Car-free cities</td>\n      <td>Write an explanatory essay to inform fellow ci...</td>\n      <td># In German Suburb, Life Goes On Without Cars ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Does the electoral college work?</td>\n      <td>Write a letter to your state senator in which ...</td>\n      <td># What Is the Electoral College? by the Office...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\ntrain_essays.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:39:12.851413Z","iopub.execute_input":"2024-01-14T19:39:12.852106Z","iopub.status.idle":"2024-01-14T19:39:12.982616Z","shell.execute_reply.started":"2024-01-14T19:39:12.852069Z","shell.execute_reply":"2024-01-14T19:39:12.981476Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"         id  prompt_id                                               text  \\\n0  0059830c          0  Cars. Cars have been around since they became ...   \n1  005db917          0  Transportation is a large necessity in most co...   \n2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n3  00940276          0  How often do you ride in a car? Do you drive a...   \n4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n\n   generated  \n0          0  \n1          0  \n2          0  \n3          0  \n4          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(train_essays)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:39:12.983781Z","iopub.execute_input":"2024-01-14T19:39:12.984116Z","iopub.status.idle":"2024-01-14T19:39:12.990134Z","shell.execute_reply.started":"2024-01-14T19:39:12.984090Z","shell.execute_reply":"2024-01-14T19:39:12.989206Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"1378"},"metadata":{}}]},{"cell_type":"code","source":"train_essays['generated'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:39:12.991333Z","iopub.execute_input":"2024-01-14T19:39:12.991653Z","iopub.status.idle":"2024-01-14T19:39:13.012321Z","shell.execute_reply.started":"2024-01-14T19:39:12.991627Z","shell.execute_reply":"2024-01-14T19:39:13.011439Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"generated\n0    1375\n1       3\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"We would need to generate more essays artificially","metadata":{}},{"cell_type":"code","source":"train_essays2 = pd.read_csv('/kaggle/input/human-vs-llm-text-corpus/data.csv')\ntake_rows = 10000\ntrain_essays2 = train_essays2.sample(take_rows)\ntrain_essays2['generated'] = np.where(train_essays2['source'] == 'Human', 0, 1)\ntrain_essays2.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:39:13.013319Z","iopub.execute_input":"2024-01-14T19:39:13.013587Z","iopub.status.idle":"2024-01-14T19:40:05.424831Z","shell.execute_reply.started":"2024-01-14T19:39:13.013563Z","shell.execute_reply":"2024-01-14T19:40:05.423873Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                     text  \\\n443187  Overwhelmingly charismatic. She also had a mem...   \n304800  The Negative Effects of Wealth in Society: Rhe...   \n113349  While it might seem morally just to not retali...   \n735453  PDFs are useful because they maintain the orig...   \n596424   The gut microbiome is a complex community of ...   \n\n                         source  prompt_id  text_length  word_count  generated  \n443187                    Human          0          707         134          0  \n304800                    Human          0        11685        1988          0  \n113349                  GPT-3.5          0          646         106          1  \n735453         Text-Davinci-002          0          240          40          1  \n596424  Nous-Hermes-LLaMA-2-13B       3483         2579         409          1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>source</th>\n      <th>prompt_id</th>\n      <th>text_length</th>\n      <th>word_count</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>443187</th>\n      <td>Overwhelmingly charismatic. She also had a mem...</td>\n      <td>Human</td>\n      <td>0</td>\n      <td>707</td>\n      <td>134</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>304800</th>\n      <td>The Negative Effects of Wealth in Society: Rhe...</td>\n      <td>Human</td>\n      <td>0</td>\n      <td>11685</td>\n      <td>1988</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>113349</th>\n      <td>While it might seem morally just to not retali...</td>\n      <td>GPT-3.5</td>\n      <td>0</td>\n      <td>646</td>\n      <td>106</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>735453</th>\n      <td>PDFs are useful because they maintain the orig...</td>\n      <td>Text-Davinci-002</td>\n      <td>0</td>\n      <td>240</td>\n      <td>40</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>596424</th>\n      <td>The gut microbiome is a complex community of ...</td>\n      <td>Nous-Hermes-LLaMA-2-13B</td>\n      <td>3483</td>\n      <td>2579</td>\n      <td>409</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_essays2['generated'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:05.425998Z","iopub.execute_input":"2024-01-14T19:40:05.426249Z","iopub.status.idle":"2024-01-14T19:40:05.433096Z","shell.execute_reply.started":"2024-01-14T19:40:05.426228Z","shell.execute_reply":"2024-01-14T19:40:05.432293Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"generated\n1    5565\n0    4435\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"train_prompts['instructions'][0]","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:05.436550Z","iopub.execute_input":"2024-01-14T19:40:05.436812Z","iopub.status.idle":"2024-01-14T19:40:05.444850Z","shell.execute_reply.started":"2024-01-14T19:40:05.436789Z","shell.execute_reply":"2024-01-14T19:40:05.443951Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'Write an explanatory essay to inform fellow citizens about the advantages of limiting car usage. Your essay must be based on ideas and information that can be found in the passage set. Manage your time carefully so that you can read the passages; plan your response; write your response; and revise and edit your response. Be sure to use evidence from multiple sources; and avoid overly relying on one source. Your response should be in the form of a multiparagraph essay. Write your essay in the space provided.'"},"metadata":{}}]},{"cell_type":"code","source":"train_essays","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:05.446102Z","iopub.execute_input":"2024-01-14T19:40:05.446457Z","iopub.status.idle":"2024-01-14T19:40:05.464075Z","shell.execute_reply.started":"2024-01-14T19:40:05.446423Z","shell.execute_reply":"2024-01-14T19:40:05.463215Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"            id  prompt_id                                               text  \\\n0     0059830c          0  Cars. Cars have been around since they became ...   \n1     005db917          0  Transportation is a large necessity in most co...   \n2     008f63e3          0  \"America's love affair with it's vehicles seem...   \n3     00940276          0  How often do you ride in a car? Do you drive a...   \n4     00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n...        ...        ...                                                ...   \n1373  fe6ff9a5          1  There has been a fuss about the Elector Colleg...   \n1374  ff669174          0  Limiting car usage has many advantages. Such a...   \n1375  ffa247e0          0  There's a new trend that has been developing f...   \n1376  ffc237e9          0  As we all know cars are a big part of our soci...   \n1377  ffe1ca0d          0  Cars have been around since the 1800's and hav...   \n\n      generated  \n0             0  \n1             0  \n2             0  \n3             0  \n4             0  \n...         ...  \n1373          0  \n1374          0  \n1375          0  \n1376          0  \n1377          0  \n\n[1378 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>prompt_id</th>\n      <th>text</th>\n      <th>generated</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0059830c</td>\n      <td>0</td>\n      <td>Cars. Cars have been around since they became ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>005db917</td>\n      <td>0</td>\n      <td>Transportation is a large necessity in most co...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>008f63e3</td>\n      <td>0</td>\n      <td>\"America's love affair with it's vehicles seem...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00940276</td>\n      <td>0</td>\n      <td>How often do you ride in a car? Do you drive a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00c39458</td>\n      <td>0</td>\n      <td>Cars are a wonderful thing. They are perhaps o...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1373</th>\n      <td>fe6ff9a5</td>\n      <td>1</td>\n      <td>There has been a fuss about the Elector Colleg...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1374</th>\n      <td>ff669174</td>\n      <td>0</td>\n      <td>Limiting car usage has many advantages. Such a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1375</th>\n      <td>ffa247e0</td>\n      <td>0</td>\n      <td>There's a new trend that has been developing f...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1376</th>\n      <td>ffc237e9</td>\n      <td>0</td>\n      <td>As we all know cars are a big part of our soci...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1377</th>\n      <td>ffe1ca0d</td>\n      <td>0</td>\n      <td>Cars have been around since the 1800's and hav...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1378 rows Ã— 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# 3. Loading Model","metadata":{}},{"cell_type":"code","source":"save_path = '/kaggle/input/essaywriting2/bert_base_uncased'\n\nmodel = BertForSequenceClassification.from_pretrained(save_path, return_dict=True)\ntokenizer = BertTokenizer.from_pretrained(save_path)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:05.465326Z","iopub.execute_input":"2024-01-14T19:40:05.465590Z","iopub.status.idle":"2024-01-14T19:40:09.283174Z","shell.execute_reply.started":"2024-01-14T19:40:05.465567Z","shell.execute_reply":"2024-01-14T19:40:09.282388Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# 4. Data Preprocessing","metadata":{}},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    \"\"\"\n    Clean and preprocesses text.\n\n    Parameters:\n    - text (str): Input text to be cleaned.\n\n    Returns:\n    str: Cleaned text after removing punctuations, tokenizing, converting to lowercase,\n         removing non-alphabetic words, and eliminating stop words.\n    \"\"\"\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n    words = text.split()  # Tokenize\n    words = [word.lower() for word in words if word.isalpha()]  # Lowercase and remove non-alphabetic words\n    words = [word for word in words if word not in stop_words]  # Remove stop words\n    return ' '.join(words)\n\ntrain_essays['clean_text'] = train_essays['text'].apply(clean_text)\ntrain_essays2['clean_text'] = train_essays2['text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:09.284262Z","iopub.execute_input":"2024-01-14T19:40:09.284563Z","iopub.status.idle":"2024-01-14T19:40:12.735895Z","shell.execute_reply.started":"2024-01-14T19:40:09.284538Z","shell.execute_reply":"2024-01-14T19:40:12.735141Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def add_elems(new_dict, input_id, token_type_id, attention_mask):\n    \"\"\"\n    Adds elements to a dictionary containing 'input_ids', 'token_type_ids', and 'attention_mask'.\n\n    Parameters:\n    - new_dict (dict): Dictionary to store tensors.\n    - input_id (torch.Tensor): Tensor representing input IDs.\n    - token_type_id (torch.Tensor): Tensor representing token type IDs.\n    - attention_mask (torch.Tensor): Tensor representing attention mask.\n\n    Returns:\n    dict: Updated dictionary with input tensors added.\n    \"\"\"\n    \n    # If the dictionary is empty, initialize it with the provided input tensors\n    if len(new_dict['input_ids'] ) == 0:\n        new_dict['input_ids'] = input_id.unsqueeze(dim = 0)\n        new_dict['token_type_ids'] = token_type_id.unsqueeze(dim = 0)\n        new_dict['attention_mask'] = attention_mask.unsqueeze(dim = 0)\n\n    # If the dictionary is not empty, concatenate the input tensors to the existing ones\n    else:\n        new_dict['input_ids'] = torch.cat([new_dict['input_ids'], input_id.unsqueeze(dim = 0)])\n        new_dict['token_type_ids'] = torch.cat([new_dict['token_type_ids'], token_type_id.unsqueeze(dim = 0)])\n        new_dict['attention_mask'] = torch.cat([new_dict['attention_mask'], attention_mask.unsqueeze(dim = 0)])\n        \n    return new_dict\n\ndef create_chunks(tokenizer, X, y):\n    \"\"\"\n    Create chunks of input data and corresponding labels for a given tokenizer.\n\n    Parameters:\n    - tokenizer (object): Tokenizer for processing input text.\n    - X (list): List of input essays.\n    - y (list): List of corresponding labels.\n\n    Returns:\n    tuple: A tuple containing a dictionary with input tensors ('input_ids', 'token_type_ids', 'attention_mask')\n           and a list of labels.\n    \"\"\"\n    \n    new_dict = {}\n    labels = []\n    new_dict['input_ids'] = []\n    new_dict['token_type_ids'] = []\n    new_dict['attention_mask'] = []\n\n    CLS = torch.tensor([101])\n    SEP = torch.tensor([102])\n    MAX_LEN = tokenizer.max_len_single_sentence\n\n    for i, train_essay in enumerate(X):\n        tokens = tokenizer(train_essay, return_tensors='pt')\n        len_tokens = len(tokens['input_ids'][0])\n        start_len = 1\n\n        while(1):\n            labels.append(y[i])\n            end_len = start_len + min(MAX_LEN, len_tokens - 2)\n            input_id = tokens['input_ids'][0][start_len:end_len]\n            input_id = torch.cat([CLS, input_id, SEP])\n\n            # If the length of the sentence is more than 512 and hence, has to be split\n            if len_tokens > MAX_LEN + 2:\n                token_type_id = tokens['token_type_ids'][0][start_len:end_len + 2]\n                attention_mask = tokens['attention_mask'][0][start_len:end_len + 2]\n\n                new_dict = add_elems(new_dict, input_id, token_type_id, attention_mask)\n\n                len_tokens -=  MAX_LEN\n                start_len = end_len\n\n            else:\n                zeros = torch.zeros(MAX_LEN - end_len + start_len)\n                input_id = torch.cat([input_id, zeros])\n                \n                single_token = tokens['token_type_ids'][0][0]\n                token_type_id = torch.full((MAX_LEN + 2,), fill_value=single_token)\n\n                attention_mask = tokens['attention_mask'][0][start_len:end_len]\n                ones = torch.ones(2)\n                attention_mask = torch.cat([ones, attention_mask, zeros])\n\n                new_dict = add_elems(new_dict, input_id, token_type_id, attention_mask)\n\n                break\n                \n    # Converting all the tensors to integer type\n    new_dict['input_ids'] = new_dict['input_ids'].to(torch.int)\n    new_dict['token_type_ids'] = new_dict['token_type_ids'].to(torch.int)\n    new_dict['attention_mask'] = new_dict['attention_mask'].to(torch.int)\n  \n    return new_dict, labels","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:12.737143Z","iopub.execute_input":"2024-01-14T19:40:12.737422Z","iopub.status.idle":"2024-01-14T19:40:12.754068Z","shell.execute_reply.started":"2024-01-14T19:40:12.737397Z","shell.execute_reply":"2024-01-14T19:40:12.753134Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"X = pd.concat([train_essays['clean_text'], train_essays2['clean_text']], ignore_index = True)\ny = pd.concat([train_essays['generated'], train_essays2['generated']], ignore_index = False)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:12.755381Z","iopub.execute_input":"2024-01-14T19:40:12.756139Z","iopub.status.idle":"2024-01-14T19:40:12.770954Z","shell.execute_reply.started":"2024-01-14T19:40:12.756105Z","shell.execute_reply":"2024-01-14T19:40:12.770161Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and validation sets\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:12.772139Z","iopub.execute_input":"2024-01-14T19:40:12.772479Z","iopub.status.idle":"2024-01-14T19:40:12.783637Z","shell.execute_reply.started":"2024-01-14T19:40:12.772450Z","shell.execute_reply":"2024-01-14T19:40:12.782741Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"encoded_train, y_train = create_chunks(tokenizer, X_train, y_train.to_list())\nencoded_val, y_val = create_chunks(tokenizer, X_val, y_val.to_list())","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:40:12.784834Z","iopub.execute_input":"2024-01-14T19:40:12.785120Z","iopub.status.idle":"2024-01-14T19:44:34.338470Z","shell.execute_reply.started":"2024-01-14T19:40:12.785096Z","shell.execute_reply":"2024-01-14T19:44:34.337332Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (771 > 512). Running this sequence through the model will result in indexing errors\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert labels to tensors\ntrain_labels = torch.tensor(y_train)\nval_labels = torch.tensor(y_val)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:44:34.346481Z","iopub.execute_input":"2024-01-14T19:44:34.346828Z","iopub.status.idle":"2024-01-14T19:44:34.361559Z","shell.execute_reply.started":"2024-01-14T19:44:34.346795Z","shell.execute_reply":"2024-01-14T19:44:34.360692Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Create TensorDatasets\ntrain_dataset = TensorDataset(encoded_train['input_ids'], encoded_train['attention_mask'], train_labels)\nval_dataset = TensorDataset(encoded_val['input_ids'], encoded_val['attention_mask'], val_labels)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:44:34.362735Z","iopub.execute_input":"2024-01-14T19:44:34.363099Z","iopub.status.idle":"2024-01-14T19:44:34.373572Z","shell.execute_reply.started":"2024-01-14T19:44:34.363067Z","shell.execute_reply":"2024-01-14T19:44:34.372645Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# DataLoader for efficient processing\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:44:34.374626Z","iopub.execute_input":"2024-01-14T19:44:34.374912Z","iopub.status.idle":"2024-01-14T19:44:34.384814Z","shell.execute_reply.started":"2024-01-14T19:44:34.374888Z","shell.execute_reply":"2024-01-14T19:44:34.384114Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Define the BERT model for sequence classification\n# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:44:34.385904Z","iopub.execute_input":"2024-01-14T19:44:34.386190Z","iopub.status.idle":"2024-01-14T19:44:34.671220Z","shell.execute_reply.started":"2024-01-14T19:44:34.386167Z","shell.execute_reply":"2024-01-14T19:44:34.670286Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define optimizer and learning rate scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\nepochs = 5","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:44:34.672559Z","iopub.execute_input":"2024-01-14T19:44:34.673237Z","iopub.status.idle":"2024-01-14T19:44:34.678988Z","shell.execute_reply.started":"2024-01-14T19:44:34.673202Z","shell.execute_reply":"2024-01-14T19:44:34.678017Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Define the BERT model for sequence classification\n# model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_train","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:44:34.680233Z","iopub.execute_input":"2024-01-14T19:44:34.680795Z","iopub.status.idle":"2024-01-14T19:44:34.696918Z","shell.execute_reply.started":"2024-01-14T19:44:34.680754Z","shell.execute_reply":"2024-01-14T19:44:34.696032Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([[  101,  4251, 14477,  ...,     0,     0,     0],\n         [  101,  2034,  2154,  ...,  2156, 11576,   102],\n         [  101,  4509,  2066,  ...,     0,     0,     0],\n         ...,\n         [  101,  4942, 13473,  ...,     0,     0,     0],\n         [  101,  6092,  2267,  ...,     0,     0,     0],\n         [  101,  5938,  2051,  ...,     0,     0,     0]], dtype=torch.int32),\n 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         ...,\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0],\n         [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32),\n 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 1, 1, 1],\n         [1, 1, 1,  ..., 0, 0, 0],\n         ...,\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0],\n         [1, 1, 1,  ..., 0, 0, 0]], dtype=torch.int32)}"},"metadata":{}}]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping to avoid exploding gradients\n        optimizer.step()\n\n    avg_train_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T19:44:34.702239Z","iopub.execute_input":"2024-01-14T19:44:34.702484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_test_chunks(tokenizer, X):\n    test_num = []\n    num_examples = []\n    new_dict = {}\n    new_dict['input_ids'] = []\n    new_dict['token_type_ids'] = []\n    new_dict['attention_mask'] = []\n\n    CLS = torch.tensor([101])\n    SEP = torch.tensor([102])\n    MAX_LEN = tokenizer.max_len_single_sentence\n\n    for i, train_essay in enumerate(X):\n        tokens = tokenizer(train_essay, return_tensors='pt')\n\n        len_tokens = len(tokens['input_ids'][0])\n\n        start_len = 1\n\n\n        while(1):\n            test_num.append(i)\n            end_len = start_len + min(MAX_LEN, len_tokens - 2)\n            input_id = tokens['input_ids'][0][start_len:end_len]\n            input_id = torch.cat([CLS, input_id, SEP])\n\n            if len_tokens > MAX_LEN + 2:\n                token_type_id = tokens['token_type_ids'][0][start_len:end_len + 2]\n                attention_mask = tokens['attention_mask'][0][start_len:end_len + 2]\n\n                new_dict = add_elems(new_dict, input_id, token_type_id, attention_mask)\n                num_examples.append(len(input_id))\n\n                len_tokens -=  MAX_LEN\n                start_len = end_len\n\n            else:\n\n                num_examples.append(len(input_id))\n                zeros = torch.zeros(MAX_LEN - end_len + start_len)\n                input_id = torch.cat([input_id, zeros])\n                \n                single_token = tokens['token_type_ids'][0][0]\n                token_type_id = torch.full((MAX_LEN + 2,), fill_value=single_token)\n\n                attention_mask = tokens['attention_mask'][0][start_len:end_len]\n                ones = torch.ones(2)\n                attention_mask = torch.cat([ones, attention_mask, zeros])\n\n                new_dict = add_elems(new_dict, input_id, token_type_id, attention_mask)\n                \n\n                break\n    new_dict['input_ids'] = new_dict['input_ids'].to(torch.int)\n    new_dict['token_type_ids'] = new_dict['token_type_ids'].to(torch.int)\n    new_dict['attention_mask'] = new_dict['attention_mask'].to(torch.int)\n    \n    test_num = np.array(test_num)\n    num_examples = np.array(num_examples)\n  \n    return new_dict, test_num, num_examples","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_essays['clean_text'] = test_essays['text'].apply(clean_text)\nX_test = test_essays['clean_text'].copy()\ntest_inputs, test_num, num_examples = create_test_chunks(tokenizer, X_test)\ntest_inputs = {key: value.to(device) for key, value in test_inputs.items()}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TensorDataset(test_inputs['input_ids'], test_inputs['attention_mask'])\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\nlogits = []\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids, attention_mask = batch\n        input_ids, attention_mask = input_ids.to(device), attention_mask.to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        if len(logits) == 0:\n            logits = outputs.logits\n        else:\n            logits = torch.cat([logits, outputs.logits])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\nnew_predictions = np.ones(len(X_test))\nlen_predictions = len(predictions)\nctr = 0\nj = -1\nfor i, prediction in enumerate(predictions):\n    if i <= j:\n        continue\n    \n    for j in range(i + 1, len_predictions):\n        if test_num[i] != test_num[j]:\n            j = j - 1\n            break\n    if i < j and i != len_predictions - 1:\n        new_predictions[ctr] = (predictions[i:j + 1] * num_examples[i: j + 1]).sum() / num_examples[i: j + 1].sum()\n    else:\n        new_predictions[ctr] = predictions[i]\n    ctr += 1\nnew_predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_essays['id'],\n    'generated': new_predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}